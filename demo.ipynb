{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd00b7cfd85d2fc43f76dbccc53202d8ba6a9a8cca408d693df58307e7c75a304a7",
   "display_name": "Python 3.8.8 64-bit ('atcs-practical': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0b7cfd85d2fc43f76dbccc53202d8ba6a9a8cca408d693df58307e7c75a304a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Demo for ACTS Assignments\n",
    "#### Rodrigo Alejandro Chavez Mulsa\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.Classifier import Classifier\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from modules.AverageEmbeddings import AverageEmbeddings\n",
    "from modules.Classifier import Classifier\n",
    "import torch\n",
    "from torchtext.legacy.datasets.nli import SNLI\n",
    "from torchtext.legacy.data import Field\n",
    "from torchtext.legacy import data\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "source": [
    "### Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_path(model_name='awe'):\n",
    "    \"\"\"Get the path to the model checkpoints. Available: [awe, lstm, bilstm, bilstm-max]\n",
    "    \"\"\"\n",
    "    return'trained_models/'+model_name+'/gold/'+model_name+'.ckpt'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(_premise,_hypothesis,model):\n",
    "    premise  = _premise.split(' ')\n",
    "    hypothesis  = _hypothesis.split(' ')\n",
    "\n",
    "    prem = TEXT.process([premise])\n",
    "    hyp = TEXT.process([hypothesis])\n",
    "\n",
    "    prem = [a.to(device) for a in prem] #Send to device\n",
    "    hyp = [a.to(device) for a in hyp] \n",
    "\n",
    "    pred = model.demo_inference(prem,hyp)\n",
    "    print(\"Premise:\",_hypothesis,'\\nHypothesis:',_hypothesis,\"\\nPredicted label -->\",pred[1],'<-- with confidence:',pred[2])"
   ]
  },
  {
   "source": [
    "## Load models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'bilstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = torchtext.vocab.GloVe(name='840B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(lower=True, include_lengths=True, batch_first=True,tokenize='spacy',tokenizer_language=\"en_core_web_sm\")\n",
    "LABEL = Field(sequential=False)\n",
    "\n",
    "train, dev, test = SNLI.splits(TEXT, LABEL, root= './data')\n",
    "TEXT.build_vocab(train, vectors=glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = MODEL#'lstm'\n",
    "checkpath = get_checkpoint_path(model_name)\n",
    "model = Classifier()\n",
    "pretrained_model = model.load_from_checkpoint(checkpath,model_name=model_name,disable_nonlinear=True).to(device)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twice cells in case we want to input some sentences but want to keep the basic example.\n",
    "premise = \"Two woman are embracing while holding to go packages\"\n",
    "hypothesis = \"Two woman are something packages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Premise: Two woman are something packages \nHypothesis: Two woman are something packages \nPredicted label --> entailment <-- with confidence: 0.8692886829376221\n"
     ]
    }
   ],
   "source": [
    "premise = \"Two woman are embracing while holding to go packages\"\n",
    "hypothesis = \"Two woman are something packages\"\n",
    "get_prediction(premise,hypothesis,pretrained_model)"
   ]
  },
  {
   "source": [
    "## Scores \n",
    "In the following table we can see the accuracy scores for the NLI dev and test set along with the micro and macro scores of the transfer task which were measured by aggregating the accuracy scores of the following transfer tasks:\n",
    " \n",
    "`transfer_tasks=['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC','MRPC', 'SICKEntailment']`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| Model      | NLI-dev | NLI-test | Transf-micro | Transf-macro |\n",
    "|------------|---------|----------|--------------|--------------|\n",
    "| AWE        | 0.6173  | 0.6283   | 82.573       | 79.129       |\n",
    "| LSTM       | 0.791   | 0.7834   | 77.41        | 78.337       |\n",
    "| BILSTM     | 0.7935  | 0.7948   | 83.36        | 82.185       |\n",
    "| BILSTM-MAX | 0.834   | 0.8333   | 87.075       | 84.95        |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For the transfer tasks I used the suggested parameters to reproduce the results from the authors which are the following:    \n",
    "`params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}`    \n",
    "`params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,'tenacity': 5, 'epoch_size': 4}`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}